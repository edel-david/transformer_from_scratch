{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU:\n",
    "    def __init__(self) -> None:\n",
    "        self._sqrt_of_2_by_pi = np.sqrt(2 / np.pi)\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, input: ArrayLike) -> np.ndarray:\n",
    "        self.input = np.asanyarray(input)\n",
    "        return (\n",
    "            0.5\n",
    "            * input\n",
    "            * (\n",
    "                1\n",
    "                + np.tanh(\n",
    "                    self._sqrt_of_2_by_pi * (input + 0.044715 * np.power(input, 3))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def backward(self, grad_output: ArrayLike) -> np.ndarray:\n",
    "        # raise NotImplementedError(\"Implement the GELU backward path\")\n",
    "        x = self.input\n",
    "        m1 = self._sqrt_of_2_by_pi\n",
    "        m2 = 0.044715\n",
    "        m3 = m1 * (x+m2 * x**3)\n",
    "        tanhm3 = np.tanh(\n",
    "                    m3\n",
    "                )\n",
    "        first = 0.5 * (\n",
    "                1\n",
    "                + tanhm3\n",
    "            )\n",
    "        second = x/2 * (1- tanhm3**2) * (m1+2*x**2 * m2*m1)\n",
    "        grad_out = (first + second) * grad_output\n",
    "        return grad_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "Gelu= GELU()\n",
    "a=np.random.random((5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_torch = torch.tensor(a.copy(),requires_grad=True)\n",
    "b_t=torch.nn.functional.gelu(a_torch)\n",
    "\n",
    "b_n = Gelu.forward(a.copy())\n",
    "b_n_grad = Gelu.backward(np.ones((5,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16532595 0.39514062 0.35139213 0.62540058 0.46784553]\n",
      "[0.16532423 0.39511543 0.35137409 0.62531816 0.46780561]\n",
      "[0.71157    0.89818485 0.86939301 1.01158035 0.94042867]\n"
     ]
    }
   ],
   "source": [
    "print(b_t.clone().detach().numpy())\n",
    "print(b_n) \n",
    "# close enough\n",
    "\n",
    "print(b_n_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7119, 0.9009, 0.8715, 1.0179, 0.9442], dtype=torch.float64),)\n",
      "[-0.00036793 -0.00267998 -0.00209933 -0.00632983 -0.00374811]\n"
     ]
    }
   ],
   "source": [
    "torch_sum = b_t.sum() # the gradient of sum equals the np.ones((5,))\n",
    "grads = torch.autograd.grad(outputs=[torch_sum],inputs=[a_torch])\n",
    "print(grads)\n",
    "diff = (b_n_grad-grads[0].detach().numpy())\n",
    "print(diff)\n",
    "assert(abs(diff).max() <= 1e-2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
