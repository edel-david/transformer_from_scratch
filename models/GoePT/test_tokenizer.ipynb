{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tokenizers import Tokenizer\n",
    "from model import GoePT\n",
    "import json\n",
    "import os\n",
    "import cupy as cp\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "wandb.init(mode=\"disabled\")\n",
    "\n",
    "\n",
    "checkpoint_filename = \"bias_fix.json\"\n",
    "with open(\n",
    "    os.path.join(\"../../checkpoints\", checkpoint_filename),\n",
    "    mode=\"r\",\n",
    "    encoding=\"utf-8\",\n",
    ") as in_file:\n",
    "    state_dict = json.load(in_file)\n",
    "model_loaded = GoePT.from_state_dict(state_dict)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer: Tokenizer = Tokenizer.from_file(\"../tokenizers/goe_pt/goe_pt_tokenizer.json\")\n",
    "# tokenizer.enable_padding(length=256)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEPHISTOPHELES:\n",
      "am Throne kniend.\n",
      "Was ist verwünscht und stets willkommen?\n",
      "Was ist ersehnt und stets verjagt?\n",
      "Was immerfort in Schutz genommen?\n",
      "Was hart gescholten und verklagt?.\n",
      "\n",
      "Und, wenn!\n",
      "FAUST. Die\n",
      "MEPHISTOPHELES ich, der; doch, was sich. Du\n",
      "Der und nicht mehr und, der;\n",
      "Der' zu.\n",
      "Der ich nicht so,\n",
      "Und ist das Herz:'ge dich'!\n",
      "MEPHISTOPHELES:s nicht mehr;\n",
      "\n",
      "Und wenn!  Er: das. Du!  und die: der Welt!, wenn, der. (nach, der sich nicht so.\n"
     ]
    }
   ],
   "source": [
    "start_text = \"\"\"MEPHISTOPHELES:\n",
    "am Throne kniend.\n",
    "Was ist verwünscht und stets willkommen?\n",
    "Was ist ersehnt und stets verjagt?\n",
    "Was immerfort in Schutz genommen?\n",
    "Was hart gescholten und verklagt?\"\"\"\n",
    "text = start_text\n",
    "print(start_text,end=\"\")\n",
    "for i in range(100):\n",
    "    tokenized = tokenizer.encode(text)\n",
    "    #print(tokenized.ids)\n",
    "    padded_tokenized = cp.array(tokenized.ids)\n",
    "    tokenized = padded_tokenized.reshape((1, -1))\n",
    "    #print(tokenized)\n",
    "    logits, _ = model_loaded.forward(tokenized)\n",
    "    #print(logits)\n",
    "    probabilites ,out = torch.topk(torch.tensor(logits),10,sorted=True)\n",
    "    out = out.cpu().numpy().flatten().tolist()\n",
    "    probabilites = probabilites.cpu().flatten()\n",
    "    probs = torch.nn.functional.softmax(probabilites,-1)\n",
    "    selected = np.random.choice(out, size=1, p=probs).tolist()\n",
    "\n",
    "    #print(out)\n",
    "\n",
    "    #to_remove = [80,8,10,3,17]\n",
    "    #for unimportant in to_remove:\n",
    "    #    try:\n",
    "    #        selected.remove(unimportant)\n",
    "    #    except:\n",
    "    #        pass\n",
    "    out = [tokenizer.decode((val,)) for val in selected]\n",
    "    #print(out)\n",
    "    text = text + out[0]\n",
    "    print(out[0],end=\"\")\n",
    "# 0: start, 1: end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.72611997e-03 -1.78618122e-03  1.22140817e-04 ...  3.81668196e-05\n",
      "   -5.32563662e-04 -1.92076851e-04]]]\n",
      "[  80    8   10    3 1344  134  389  181   17  139]\n",
      "['\\n', ',', '.', '!', ' Du', ' und', ' Er', ' ist', ':', ' ich']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logits, _ = model_loaded.forward(tokenized)\n",
    "\n",
    "\n",
    "print(logits)\n",
    "out = torch.topk(torch.tensor(logits),10,sorted=True)[1]\n",
    "out = out.cpu().numpy().flatten()\n",
    "print(out)\n",
    "out = [tokenizer.decode((val,)) for val in out]\n",
    "print(out)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
